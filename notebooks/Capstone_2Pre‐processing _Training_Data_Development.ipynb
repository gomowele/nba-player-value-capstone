{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36982829-e77a-45a8-a783-b23388f9bec9",
   "metadata": {},
   "source": [
    "# Capstone Two: Pre‐processing & Training Data Development\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "431a3868-5d69-49ef-a9cb-11b51c658487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0) imports\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.impute           import SimpleImputer\n",
    "from sklearn.pipeline         import Pipeline\n",
    "from sklearn.preprocessing    import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose          import ColumnTransformer\n",
    "from sklearn.model_selection  import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "34c464da-f5d2-45dc-afb7-010656cfb879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) load the three CSVs\n",
    "adv = pd.read_csv(\"advanced_player_stats_checked.csv\")   # advanced metrics\n",
    "raw = pd.read_csv(\"nba_player_stats_checked.csv\")       # basic stats\n",
    "sal = pd.read_csv(\"nba_salary_checked.csv\")             # salaries\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "727823e6-e0e0-4b6d-b359-ea00403f51fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) fix salary table so it matches the others\n",
    "sal = sal.rename(columns={\"Tm\": \"Team\"})               # Tm → Team\n",
    "sal = sal[[\"Player\", \"Team\", \"2024-25\"]].rename(columns={\"2024-25\": \"Salary\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "555fd0a0-4e1b-4a50-bcdc-5950d042a790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after merge, df.shape = (270, 59)\n"
     ]
    }
   ],
   "source": [
    "# 3) merge advanced + raw on Player & Team, then add salary\n",
    "df = (adv\n",
    "      .merge(raw, on=[\"Player\",\"Team\"], how=\"inner\")\n",
    "      .merge(sal, on=[\"Player\",\"Team\"], how=\"inner\"))\n",
    "print(\"after merge, df.shape =\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "70e3ea6b-7909-467f-9f7f-57c17f751bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) drop any columns that are entirely empty (like Awards_x)\n",
    "df = df.dropna(axis=1, how=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f1292455-4345-4806-aa11-ae3a3cdb7e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) split into features X and target y\n",
    "X = df.drop(columns=[\"Player\",\"Salary\"])\n",
    "y = df[\"Salary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f98e187c-d4f6-4249-8844-f0ec9d812eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (202, 56) X_test.shape: (68, 56)\n"
     ]
    }
   ],
   "source": [
    "# 6) train/test split (25% holdout)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42\n",
    ")\n",
    "print(\"X_train.shape:\", X_train.shape, \"X_test.shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d5ce9e22-2a44-49dc-96fa-d900cc80ecb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numeric_cols: ['Rk_x', 'Age_x', 'G_x', 'GS_x', 'MP_x', 'PER', 'TS%', '3PAr', 'FTr', 'ORB%', 'DRB%', 'TRB%', 'AST%', 'STL%', 'BLK%', 'TOV%', 'USG%', 'OWS', 'DWS', 'WS', 'WS/48', 'OBPM', 'DBPM', 'BPM', 'VORP', 'Rk_y', 'Age_y', 'G_y', 'GS_y', 'MP_y', 'FG', 'FGA', 'FG%', '3P', '3PA', '3P%', '2P', '2PA', '2P%', 'eFG%', 'FT', 'FTA', 'FT%', 'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS']\n",
      "categorical_cols: ['Team', 'Pos_x', 'Pos_y', 'Awards_y']\n"
     ]
    }
   ],
   "source": [
    "# 7) identify numeric vs. categorical columns\n",
    "numeric_cols     = X.select_dtypes(include=np.number).columns.tolist()\n",
    "categorical_cols = X.select_dtypes(exclude=np.number).columns.tolist()\n",
    "print(\"numeric_cols:\", numeric_cols)\n",
    "print(\"categorical_cols:\", categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "75db5d95-d180-4b57-bae1-4ff0648ce53b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 8) build pipelines\n",
    "num_pipe = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),  # fill NaNs with median\n",
    "    (\"scaler\",  StandardScaler()),                  # then standardize\n",
    "])\n",
    "cat_pipe = Pipeline([\n",
    "    (\"ohe\", OneHotEncoder(\n",
    "        sparse_output=False,      # dense array\n",
    "        drop=\"first\",             # avoid dummy trap\n",
    "        handle_unknown=\"ignore\"   # unseen cats → all zeros\n",
    "    )),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "36a3b056-04c0-4981-95a8-45dfef56faf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9) combine into a ColumnTransformer\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"nums\", num_pipe,     numeric_cols),\n",
    "    (\"cats\", cat_pipe,     categorical_cols),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9e680fa7-2d57-4955-81bb-f0d2cc254a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed shapes: (202, 116) (68, 116)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/preprocessing/_encoders.py:242: UserWarning: Found unknown categories in columns [3] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 10) fit on TRAIN only & transform both\n",
    "preprocessor.fit(X_train)\n",
    "X_train_prep = preprocessor.transform(X_train)\n",
    "X_test_prep  = preprocessor.transform(X_test)\n",
    "\n",
    "print(\"processed shapes:\", X_train_prep.shape, X_test_prep.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50179e94-a09b-41ef-a145-998293c79dfd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
